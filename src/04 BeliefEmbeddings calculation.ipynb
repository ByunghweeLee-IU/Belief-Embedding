{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e9060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import font_manager as fm\n",
    "from matplotlib import rc\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import models, SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18cfe8b",
   "metadata": {},
   "source": [
    "## 1. Load dataset, model, get stance vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed928ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#epoch3 ver. \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_idx \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m]: \u001b[38;5;66;03m#[0,1,2,3,4]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#1.Load data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     df_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../dataset/04_K-fold_dataset/df_train_idx\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.p\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(data_idx))\n\u001b[1;32m      7\u001b[0m     df_test  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../dataset/04_K-fold_dataset/df_test_idx\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.p\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(data_idx))\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mlen\u001b[39m(df_train), \u001b[38;5;28mlen\u001b[39m(df_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#user model with epoch3 ver. \n",
    "\n",
    "for data_idx in [0]: #[0,1,2,3,4]\n",
    "\n",
    "    #1.Load data\n",
    "    df_train = pd.read_pickle('../dataset/04_K-fold_dataset/df_train_idx%d.p'%(data_idx))\n",
    "    df_test  = pd.read_pickle('../dataset/04_K-fold_dataset/df_test_idx%d.p'%(data_idx))\n",
    "\n",
    "    \n",
    "    len(df_train), len(df_test)\n",
    "\n",
    "    train_titles = df_train.debate_title.unique()\n",
    "    test_titles = df_test.debate_title.unique()\n",
    "\n",
    "    print(\"data %d\"%(data_idx))\n",
    "    print(f\"There are {len(train_titles)} debate titles in train datasets\")\n",
    "    print(f\"There are {len(test_titles)} debate titles in test datasets\")\n",
    "\n",
    "    train_stances = df_train.belief_statement.unique()\n",
    "    test_stances = df_test.belief_statement.unique()\n",
    "\n",
    "    print(f\"There are {len(train_stances)} debate stances in train datasets\")\n",
    "    print(f\"There are {len(test_stances)} debate stances in test datasets\")\n",
    "\n",
    "\n",
    "    #2.Load model\n",
    "\n",
    "    #BERT Model\n",
    "    bert = models.Transformer('bert-base-uncased')\n",
    "    pooler = models.Pooling(\n",
    "        bert.get_word_embedding_dimension(), #768\n",
    "        pooling_mode_mean_tokens=True #mean pooling\n",
    "    )\n",
    "    model_bert = SentenceTransformer(modules=[bert, pooler])\n",
    "\n",
    "\n",
    "    #Fine-tuned BERT model\n",
    "    MODEL_PATH = '../model/finetuned-BERT_idx%d_epoch3'%(data_idx)\n",
    "    model_bert_ft = SentenceTransformer(MODEL_PATH)\n",
    "\n",
    "    #roberta-base\n",
    "    model_roberta_base = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')       \n",
    "\n",
    "    #finetuned roberta-base\n",
    "    MODEL_PATH = '../model/roberta-base_idx%d_epoch3'%(data_idx)\n",
    "    model_roberta_base_ft = SentenceTransformer(MODEL_PATH)\n",
    "\n",
    "    #3. Get embedding vector    \n",
    "    model_list = [model_bert, model_bert_ft, model_roberta_base, model_roberta_base_ft]\n",
    "    model_labels = ['model_bert','model_bert_ft', 'model_roberta-base', 'model_roberta-base_ft']\n",
    "\n",
    "    for m_idx, model in enumerate(model_list):\n",
    "        print(model_labels[m_idx])\n",
    "\n",
    "        train_embeddings = [] \n",
    "        for e in tqdm(train_stances):\n",
    "            train_embeddings.append(model.encode(e))\n",
    "\n",
    "        train_stance2embeddings = {}\n",
    "        for i in range(len(train_stances)):\n",
    "            train_stance2embeddings[train_stances[i]] = train_embeddings[i]\n",
    "\n",
    "        with open('../dataset/BeliefEmbeddingResults/BeliefEmbeddings_data(%d)_model(%s).p'%(data_idx, model_labels[m_idx]), 'wb') as f:\n",
    "            pickle.dump(train_stance2embeddings, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842615c-7ba3-4446-b775-756a522ff833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
