{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d35acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from collections import defaultdict \n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import models, SentenceTransformer\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers import losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers.evaluation import TripletEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485277e0",
   "metadata": {},
   "source": [
    "## Generation of belief triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2082ec7e",
   "metadata": {},
   "source": [
    "### Read dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e92cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../dataset/01_Final_dataframe/df_ddo_including_only_truebeliefs_nodup(N192307).p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bdbce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debate_key</th>\n",
       "      <th>debate_title</th>\n",
       "      <th>username</th>\n",
       "      <th>debate_date</th>\n",
       "      <th>position</th>\n",
       "      <th>is_belief</th>\n",
       "      <th>belief_statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.-Audis-are-junkers-except-to-rich-kids-with-l...</td>\n",
       "      <td>. Audis are junkers, except to rich kids with ...</td>\n",
       "      <td>Max.Wallace</td>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>Pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I agree with the following: . Audis are junker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>....-Former-Secretary-of-State-Madeleine-Albri...</td>\n",
       "      <td>....\"Former Secretary of State Madeleine Albri...</td>\n",
       "      <td>Lookingatissues</td>\n",
       "      <td>2017-01-30</td>\n",
       "      <td>Pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I agree with the following: ....\"Former Secret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...Words-can-t-hurt-me-any./1/</td>\n",
       "      <td>...Words can't hurt me any.</td>\n",
       "      <td>NonInDelicto</td>\n",
       "      <td>2007-12-19</td>\n",
       "      <td>Pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I agree with the following: ...Words can't hur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.9-repeated-is-equal-to-1./1/</td>\n",
       "      <td>.9 repeated is equal to 1.</td>\n",
       "      <td>cowpie1998</td>\n",
       "      <td>2011-04-07</td>\n",
       "      <td>Pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I agree with the following: .9 repeated is equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.99-is-equal-to-one./1/</td>\n",
       "      <td>.99 is equal to one.</td>\n",
       "      <td>SweetCrackerJack</td>\n",
       "      <td>2013-12-24</td>\n",
       "      <td>Pro</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I agree with the following: .99 is equal to one.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          debate_key  \\\n",
       "1  .-Audis-are-junkers-except-to-rich-kids-with-l...   \n",
       "2  ....-Former-Secretary-of-State-Madeleine-Albri...   \n",
       "3                     ...Words-can-t-hurt-me-any./1/   \n",
       "4                      .9-repeated-is-equal-to-1./1/   \n",
       "5                            .99-is-equal-to-one./1/   \n",
       "\n",
       "                                        debate_title          username  \\\n",
       "1  . Audis are junkers, except to rich kids with ...       Max.Wallace   \n",
       "2  ....\"Former Secretary of State Madeleine Albri...   Lookingatissues   \n",
       "3                        ...Words can't hurt me any.      NonInDelicto   \n",
       "4                         .9 repeated is equal to 1.        cowpie1998   \n",
       "5                               .99 is equal to one.  SweetCrackerJack   \n",
       "\n",
       "  debate_date position  is_belief  \\\n",
       "1  2014-09-04      Pro        1.0   \n",
       "2  2017-01-30      Pro        1.0   \n",
       "3  2007-12-19      Pro        1.0   \n",
       "4  2011-04-07      Pro        1.0   \n",
       "5  2013-12-24      Pro        1.0   \n",
       "\n",
       "                                    belief_statement  \n",
       "1  I agree with the following: . Audis are junker...  \n",
       "2  I agree with the following: ....\"Former Secret...  \n",
       "3  I agree with the following: ...Words can't hur...  \n",
       "4  I agree with the following: .9 repeated is equ...  \n",
       "5   I agree with the following: .99 is equal to one.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85983d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size: 192307\n",
      "num debates: 65861\n",
      "num debate title: 59986\n",
      "num users: 40280\n",
      "average participation: 4.7742552135054614\n",
      "Unique beliefs 119972\n"
     ]
    }
   ],
   "source": [
    "print('data size:', len(df))\n",
    "print('num debates:', len(df['debate_key'].unique()))\n",
    "print('num debate title:', len(df['debate_title'].unique()))\n",
    "print('num users:', len(df['username'].unique()))\n",
    "print('average participation:', len(df)/len(df['username'].unique())  )\n",
    "print('Unique beliefs', len(df['belief_statement'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a73e51",
   "metadata": {},
   "source": [
    "### Generate 5-fold dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374572d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59986 unique debates in debate.org dataset\n"
     ]
    }
   ],
   "source": [
    "debate_titles = df.debate_title.unique()\n",
    "print(f\"There are {len(debate_titles)} unique debates in debate.org dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752dc74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(debate_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e393f320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[11998 11999 12000 ... 59983 59984 59985]\n",
      "  Test:  index=[    0     1     2 ... 11995 11996 11997]\n",
      "47988 11998\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 59983 59984 59985]\n",
      "  Test:  index=[11998 11999 12000 ... 23992 23993 23994]\n",
      "47989 11997\n",
      "Fold 2:\n",
      "  Train: index=[    0     1     2 ... 59983 59984 59985]\n",
      "  Test:  index=[23995 23996 23997 ... 35989 35990 35991]\n",
      "47989 11997\n",
      "Fold 3:\n",
      "  Train: index=[    0     1     2 ... 59983 59984 59985]\n",
      "  Test:  index=[35992 35993 35994 ... 47986 47987 47988]\n",
      "47989 11997\n",
      "Fold 4:\n",
      "  Train: index=[    0     1     2 ... 47986 47987 47988]\n",
      "  Test:  index=[47989 47990 47991 ... 59983 59984 59985]\n",
      "47989 11997\n"
     ]
    }
   ],
   "source": [
    "train_indices = []\n",
    "test_indices  = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(debate_titles)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")  \n",
    "    print(f\"  Test:  index={test_index}\")    \n",
    "    print(len(train_index), len(test_index))\n",
    "\n",
    "    train_indices.append(train_index)\n",
    "    test_indices.append(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd0a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    train_titles = debate_titles[train_indices[i]]\n",
    "    test_titles = debate_titles[test_indices[i]]\n",
    "    df_train = df[df['debate_title'].isin(train_titles)]\n",
    "    df_test  = df[df['debate_title'].isin(test_titles)]\n",
    "        \n",
    "    df_train.to_pickle('../dataset/04_K-fold_dataset/df_train_idx%d.p'%(i))\n",
    "    df_test.to_pickle('../dataset/04_K-fold_dataset/df_test_idx%d.p'%(i))\n",
    "    \n",
    "    #print(\"Train size:\",len(df_train), \"Test size:\",len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e39e1",
   "metadata": {},
   "source": [
    "### Generate triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e765177",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_phrase = 'I agree with the following: '\n",
    "con_phrase = 'I disagree with the following: '\n",
    "\n",
    "def get_reverse_phrase(phrase):\n",
    "    if phrase == pro_phrase:\n",
    "        return con_phrase\n",
    "    elif phrase == con_phrase:\n",
    "        return pro_phrase\n",
    "    else: \n",
    "        print('error')\n",
    "        \n",
    "def get_opposite_belief(belief_statement):\n",
    "    position = \" \".join(belief_statement.split()[:5]) + ' '\n",
    "    title = \" \".join(belief_statement.split()[5:]) \n",
    "    \n",
    "    position_r = get_reverse_phrase(position)\n",
    "    opposite_belief = position_r + title\n",
    "    return opposite_belief        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0627519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I disagree with the following: apples are delicious.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example \n",
    "get_opposite_belief('I agree with the following: apples are delicious.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6937580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a belief co-occurrence dictionary\n",
    "def get_belief_cooccurrence_dic(df):\n",
    "    \n",
    "    df_g = df.groupby('username')\n",
    "    corpus = []\n",
    "\n",
    "    for g, data in df_g:\n",
    "\n",
    "        data = data.sort_values(by='debate_date')\n",
    "        user_beliefs = list(data['belief_statement'].unique())\n",
    "        corpus.append(user_beliefs)\n",
    "        \n",
    "    \n",
    "    belief2list = defaultdict(list)\n",
    "    \n",
    "    for b_list in corpus:\n",
    "        if len(b_list) == 1: \n",
    "            continue\n",
    "\n",
    "        for e1 in b_list:\n",
    "            for e2 in b_list:\n",
    "                if e1 != e2:\n",
    "                    belief2list[e1].append(e2)\n",
    "                    \n",
    "    return belief2list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "381fb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_co = get_belief_cooccurrence_dic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faf16d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102881"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f731a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get triplets using the belief co-occurrence dictionary\n",
    "def get_stance_triplet(belief2list):\n",
    "    \n",
    "    belief_triplet = []\n",
    "\n",
    "    for s in tqdm(belief2list):\n",
    "\n",
    "        anchor = s\n",
    "        positive_samples = belief2list[s] \n",
    "        opposite_belief = get_opposite_belief(s)\n",
    "\n",
    "        if not opposite_belief in belief2list: #use only direct opposite stance as a negative sample\n",
    "            negative_samples = [opposite_belief]\n",
    "        else:\n",
    "            negative_samples = [opposite_belief] + belief2list[opposite_belief]\n",
    "\n",
    "        #if vote history is too long: Sample 5 stances from history \n",
    "        thres = 5\n",
    "        if len(positive_samples) > thres-1:\n",
    "            positive_samples = np.random.choice(positive_samples, size=thres, replace=False)\n",
    "\n",
    "        if len(negative_samples) > thres-1:\n",
    "            #to ensure including directly opposite stance\n",
    "            other_samples = np.random.choice(negative_samples[1:], size=thres-1, replace=False)        \n",
    "            negative_samples = np.concatenate((negative_samples[:1], other_samples)) \n",
    "\n",
    "        #make triplet examples \n",
    "        for pos in positive_samples:\n",
    "            for neg in negative_samples:\n",
    "                example = [anchor, pos, neg]\n",
    "                belief_triplet.append(example)\n",
    "    \n",
    "    return belief_triplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d42cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(5)):\n",
    "    df_train = pd.read_pickle('../dataset/04_K-fold_dataset/df_train_idx%d.p'%(i))\n",
    "    df_test = pd.read_pickle('../dataset/04_K-fold_dataset/df_test_idx%d.p'%(i))\n",
    "\n",
    "    belief2list_train = get_belief_cooccurrence_dic(df_train)\n",
    "    belief2list_test  = get_belief_cooccurrence_dic(df_test)\n",
    "    \n",
    "    train_triplets = get_stance_triplet(belief2list_train)\n",
    "    test_triplets  = get_stance_triplet(belief2list_test)\n",
    "    \n",
    "    with open('../dataset/04_K-fold_triplets/train_triplet_idx%d.p'%i,'wb') as f:\n",
    "        pickle.dump(train_triplets, f)\n",
    "        \n",
    "    with open('../dataset/04_K-fold_triplets/test_triplet_idx%d.p'%i,'wb') as f:\n",
    "        pickle.dump(test_triplets, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4012409",
   "metadata": {},
   "source": [
    "## Train / Test set with commonly appearing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ead1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset idx:0\n",
      "# votes: Train, Train_common, Test, Test_common\n",
      "153698 111724 38609 33208\n",
      "# voters: Train, Train_common, Test, Test_common\n",
      "35447 10173 15006 10173\n",
      "\n",
      "Dataset idx:1\n",
      "# votes: Train, Train_common, Test, Test_common\n",
      "151618 110860 40689 35171\n",
      "# voters: Train, Train_common, Test, Test_common\n",
      "35362 10401 15319 10401\n",
      "\n",
      "Dataset idx:2\n",
      "# votes: Train, Train_common, Test, Test_common\n",
      "151524 107163 40783 36060\n",
      "# voters: Train, Train_common, Test, Test_common\n",
      "36092 9706 13894 9706\n",
      "\n",
      "Dataset idx:3\n",
      "# votes: Train, Train_common, Test, Test_common\n",
      "157602 113625 34705 27733\n",
      "# voters: Train, Train_common, Test, Test_common\n",
      "34205 9675 15750 9675\n",
      "\n",
      "Dataset idx:4\n",
      "# votes: Train, Train_common, Test, Test_common\n",
      "154786 110227 37521 33007\n",
      "# voters: Train, Train_common, Test, Test_common\n",
      "36220 9744 13804 9744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sets = []\n",
    "test_sets  = []\n",
    "\n",
    "BASE_PATH = '../dataset/04_K-fold_dataset/'\n",
    "\n",
    "for i in range(5):    \n",
    "    \n",
    "    df_train = pd.read_pickle(BASE_PATH + 'df_train_idx%d.p'%(i))\n",
    "    df_test  = pd.read_pickle(BASE_PATH + 'df_test_idx%d.p'%(i))\n",
    "        \n",
    "    train_users = df_train.username.unique()\n",
    "    test_users  = df_test.username.unique()\n",
    "    \n",
    "    common_users = []\n",
    "    for u in test_users:\n",
    "        if u in train_users:\n",
    "            common_users.append(u)\n",
    "    \n",
    "    df_train_common = df_train[df_train['username'].isin(common_users)]\n",
    "    df_test_common  = df_test[df_test['username'].isin(common_users)]\n",
    "    \n",
    "    \n",
    "    train_sets.append(df_train_common)\n",
    "    test_sets.append(df_test_common)\n",
    "    \n",
    "    print(\"Dataset idx:%d\"%(i))\n",
    "    print(\"# votes: Train, Train_common, Test, Test_common\")\n",
    "    print(len(df_train), len(df_train_common), len(df_test), len(df_test_common))\n",
    "    print(\"# voters: Train, Train_common, Test, Test_common\")\n",
    "    print(len(df_train.username.unique()), len(df_train_common.username.unique()), len(df_test.username.unique()), len(df_test_common.username.unique()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '../dataset/04_K-fold_dataset_commonusers/'\n",
    "\n",
    "for i in range(5):    \n",
    "    \n",
    "    train_sets[i].to_pickle(BASE_PATH + 'df_commonuser_train_idx%d.p'%(i))\n",
    "    test_sets[i].to_pickle(BASE_PATH + 'df_commonuser_test_idx%d.p'%(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df75cc",
   "metadata": {},
   "source": [
    "## Fine-tuing Sentence-BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe04fd38",
   "metadata": {},
   "source": [
    "### Training S-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301edb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_index in range(5): #iteration over K-fold \n",
    "\n",
    "    #Load dataset \n",
    "    filepath = '../dataset/04_K-fold_triplets/train_triplet_idx%d.p'%(data_index) \n",
    "\n",
    "    with open(filepath,'rb') as f:\n",
    "        triplet_data = pickle.load(f)\n",
    "\n",
    "    #Make InputExamples to use it as input for Data loader \n",
    "    triplets = []\n",
    "    for e in tqdm(triplet_data):\n",
    "        triplets.append(InputExample(texts = e))\n",
    "\n",
    "    #Data Loader \n",
    "    batch_size = 32\n",
    "    loader = DataLoader(triplets, shuffle=True, batch_size=batch_size)    \n",
    "   \n",
    "    num_epochs = 5\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        print(\"Dataidx: %d, epoch: %d\"%(data_index, epoch))\n",
    "        \n",
    "        if epoch == 0:\n",
    "            model = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')        \n",
    "        else:\n",
    "            model = SentenceTransformer('../model/roberta-base_idx%d_epoch%d'%(data_index, epoch))\n",
    "            \n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model.to(device)\n",
    "\n",
    "        loss = losses.TripletLoss(model)\n",
    "        savepath = '../model/roberta-base_idx%d_epoch%d'%(data_index, epoch+1)\n",
    "        \n",
    "        model.fit(\n",
    "            train_objectives=[(loader, loss)],\n",
    "            epochs=1,\n",
    "            output_path=savepath,\n",
    "            show_progress_bar=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f458cb",
   "metadata": {},
   "source": [
    "### Training original-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_index in range(5): \n",
    "\n",
    "    #Load dataset \n",
    "    filepath = '../dataset/04_K-fold_triplets/train_triplet_idx%d.p'%(data_index) \n",
    "\n",
    "    with open(filepath,'rb') as f:\n",
    "        triplet_data = pickle.load(f)\n",
    "\n",
    "    print(f\"Total # tripliets : {len(triplet_data)}\")\n",
    "\n",
    "    \n",
    "    #Make InputExamples to use it as input for Data loader \n",
    "    triplets = []\n",
    "    for e in tqdm(triplet_data):\n",
    "        triplets.append(InputExample(texts = e))\n",
    "\n",
    "    #Data Loader \n",
    "    batch_size = 32\n",
    "    loader = DataLoader(triplets, shuffle=True, batch_size=batch_size)    \n",
    "\n",
    "\n",
    "    #Model preparation - BERT \n",
    "    bert = models.Transformer('bert-base-uncased')\n",
    "\n",
    "    pooler = models.Pooling(\n",
    "                bert.get_word_embedding_dimension(), #768\n",
    "                    pooling_mode_mean_tokens=True #mean pooling\n",
    "                    )\n",
    "    model = SentenceTransformer(modules=[bert, pooler])\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    print(\"device: \", model.device)\n",
    "\n",
    "\n",
    "    #Train model \n",
    "    loss = losses.TripletLoss(model)\n",
    "    epochs = 5\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        savepath = '../model/finetuned-BERT_idx%d_epoch%d'%(data_index, epoch+1)\n",
    "        \n",
    "        model.fit(\n",
    "            train_objectives=[(loader, loss)],\n",
    "            epochs=1,\n",
    "            output_path=savepath,\n",
    "            show_progress_bar=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db1693",
   "metadata": {},
   "source": [
    "# 02 Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac2864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
